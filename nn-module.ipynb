{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec3841f7",
   "metadata": {},
   "source": [
    "# The nn module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fc3db2",
   "metadata": {},
   "source": [
    "The torch.nn module in Pytorch is a core library that provide a wide array of classws and functionns designed to help developers build neural network efficiently and effectively. It abstracts the complexity of creating and traing neural networks by offering pre build layers, experimenting with model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a442b1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create model class\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self, num_features):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(num_features, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, features):\n",
    "        linear_output = self.linear(features)\n",
    "        y_predicted = self.sigmoid(linear_output)\n",
    "        return y_predicted    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "757c0596",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3326],\n",
       "        [0.2837],\n",
       "        [0.3381],\n",
       "        [0.3138],\n",
       "        [0.3479],\n",
       "        [0.3575],\n",
       "        [0.2889],\n",
       "        [0.2994],\n",
       "        [0.3337],\n",
       "        [0.3733]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dataset\n",
    "features = torch.rand(10, 5)\n",
    "\n",
    "# create model\n",
    "model = Model(num_features=5)\n",
    "\n",
    "# call model for forward pass\n",
    "model(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29c8d05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.1068, -0.2377,  0.1899, -0.2470, -0.3872]], requires_grad=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show model weights\n",
    "model.linear.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "928cdb06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Model                                    [10, 1]                   --\n",
       "├─Linear: 1-1                            [10, 1]                   6\n",
       "├─Sigmoid: 1-2                           [10, 1]                   --\n",
       "==========================================================================================\n",
       "Total params: 6\n",
       "Trainable params: 6\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 0.00\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.00\n",
       "Params size (MB): 0.00\n",
       "Estimated Total Size (MB): 0.00\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "summary(model, input_size=(10, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0a1853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imroved code Sequential API\n",
    "\n",
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self, num_features):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(num_features, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, features):\n",
    "        return self.network(features)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0dec584",
   "metadata": {},
   "source": [
    "## The torch.optim module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47d4bda",
   "metadata": {},
   "source": [
    "torch.optim is a module in Pytorch that provides a variety of optimization algorithms used to update tje parameters of your modle during training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72690e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "## The torch.optim module\n",
    "import torch.optim as optim\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "# optimizer = optim.RMSprop(model.parameters(), lr=0.001)\n",
    "# optimizer = optim.Adagrad(model.parameters(), lr=0.01)\n",
    "# optimizer = optim.Adadelta(model.parameters(), lr=1.0)\n",
    "# optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
    "# optimizer = optim.SparseAdam(model.parameters(), lr=0.001)\n",
    "# optimizer = optim.LBFGS(model.parameters(), lr=0.01)\n",
    "# optimizer = optim.Rprop(model.parameters(), lr=0.01)\n",
    "# optimizer = optim.ASGD(model.parameters(), lr=0.01)\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=\n",
    "# 0.9, weight_decay=1e-4, nesterov=True)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "# optimizer = optim.RMSprop(model.parameters(), lr=0.001, alpha=0.99, eps=1e-08, weight_decay=0, momentum=0, centered=False)\n",
    "# optimizer = optim.Adagrad(model.parameters(), lr=0.01, lr_decay=0, weight_decay=0, initial_accumulator_value=0, eps=1e-10)\n",
    "# optimizer = optim.Adadelta(model.parameters(), lr=1.0, rho=0.9, eps=1e-06, weight_decay=0)\n",
    "# optimizer = optim.AdamW(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.01, amsgrad=False)\n",
    "# optimizer = optim.SparseAdam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08)\n",
    "# optimizer = optim.LBFGS(model.parameters(), lr=0.01, max_iter=20, max_eval=None, tolerance_grad=1e-07, tolerance_change=1e-09, history_size=100, line_search_fn=None)\n",
    "# optimizer = optim.Rprop(model.parameters(), lr=0.01, etas=(0.5, 1.2), step_sizes=(1e-06, 50))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
